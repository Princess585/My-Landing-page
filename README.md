# My Landing page
Data Visualization project
We create a website that visualizes data using tools and zoom  to provide an accessible way to see and understand trends, outliers, and patterns in data.
https://princess585.github.io/My-Landing-page/ link to my landing page
Team members

Princess Daisy Khombisa
Role: Front and backend developer
Will oversee the entire project, ensuring that timelines and resources are met and allocated, collect, clean, and analyze the data that will be used, and I will create the visual representations of the data.

Technologies

Libraries: 
-D3.js: Data-Driven Documents is a JavaScript library for producing dynamic, data visualizations in web browsers using HTML and CSS.
-NumPy: A fundamental library for numerical calculating in Python. 
-Seaborn: A type of python data visualization library that provides a high-level interface for drawing attractive and data statistical graphics.

Languages:
-Python
-JavaScript

Linkedin article link - https://www.linkedin.com/pulse/data-visualization-princess-khombisa-mqgyf/?trackingId=Vi8mZ0r1TZW%2FIc%2FNPURgMQ%3D%3D
Author - Princess Daisy Khombisa

The most difficult technical challenge

One of the most challenging technical hurdles I encountered while working on our data visualization project was ensuring the application's capability to efficiently handle large datasets without compromising performance. Early in the development phase, we faced significant lag and performance issues when users tried to upload and visualize large datasets. This posed a problem as our application's key feature was its real-time processing and display of comprehensive datasets. The lag not only impacted user experience but also jeopardized the accuracy and reliability of the visualizations. My responsibility was to optimize the application to seamlessly handle large datasets, ensuring swift processing and responsive visualizations. This involved identifying and addressing bottlenecks in both the frontend and backend of the application. I began by profiling the application to identify the source of the performance issues. I discovered that the primary bottlenecks were related to data processing and rendering. On the backend, I improved our data handling by implementing efficient data structures and algorithms for processing. I also utilized Django's built-in pagination to load data in chunks rather than all at once, significantly reducing the loading time. For the frontend, I employed lazy loading techniques and optimized the D3.js visualizations to initially render only the necessary data points. Additionally, I integrated Web Workers to offload resource-intensive computations from the main thread, ensuring a responsive user interface even during intensive processing tasks. These optimizations resulted in a significant enhancement in performance. The application could now effortlessly handle large datasets, processing and rendering visualizations in a fraction of the time it took earlier. Users experienced a smooth and responsive interface, even when working with extensive and complex datasets. These improvements not only met the initial project requirements but also greatly enhanced user satisfaction and engagement, validating the success of the implemented solutions.

Doing this project I got help from The book - storytelling with data by Cole Nussbaumer Knaflic 
Link - https://docs.google.com/document/d/1aSuqNXSSAMHcHjWD-TOl7_J7lZvHP06INls7nLXavKs/edit
